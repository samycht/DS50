{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de88e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torchvision as tv\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import wandb\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e954ad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'DenseNet_V2'\n",
    "BATCH_SIZE = 2\n",
    "MAX_TRAIN_BATCHES = 305\n",
    "MAX_VAL_BATCHES = 35\n",
    "MAX_TEST_BATCHES = 155\n",
    "NB_EPOCHS = 3\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99dfc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Labelling\n",
    "train_img_dir_path = 'images/train'\n",
    "valid_img_dir_path = 'images/valid'\n",
    "test_img_dir_path = 'images/test'\n",
    "\n",
    "train_normal_images = [f'{train_img_dir_path}/normal/{i}' for i in listdir(f'{train_img_dir_path}/normal')]\n",
    "train_adenocarcinoma_images = [f'{train_img_dir_path}/adenocarcinoma/{i}' for i in listdir(f'{train_img_dir_path}/adenocarcinoma')]\n",
    "train_largecell_carcinoma_images = [f'{train_img_dir_path}/large.cell.carcinoma/{i}' for i in listdir(f'{train_img_dir_path}/large.cell.carcinoma')]\n",
    "train_squamouscell_carcinoma_images = [f'{train_img_dir_path}/squamous.cell.carcinoma/{i}' for i in listdir(f'{train_img_dir_path}/squamous.cell.carcinoma')]\n",
    "\n",
    "valid_normal_images = [f'{valid_img_dir_path}/normal/{i}' for i in listdir(f'{valid_img_dir_path}/normal')]\n",
    "valid_adenocarcinoma_images = [f'{valid_img_dir_path}/adenocarcinoma/{i}' for i in listdir(f'{valid_img_dir_path}/adenocarcinoma')]\n",
    "valid_largecell_carcinoma_images = [f'{valid_img_dir_path}/large.cell.carcinoma/{i}' for i in listdir(f'{valid_img_dir_path}/large.cell.carcinoma')]\n",
    "valid_squamouscell_carcinoma_images = [f'{valid_img_dir_path}/squamous.cell.carcinoma/{i}' for i in listdir(f'{valid_img_dir_path}/squamous.cell.carcinoma')]\n",
    "\n",
    "test_normal_images = [f'{test_img_dir_path}/normal/{i}' for i in listdir(f'{test_img_dir_path}/normal')]\n",
    "test_adenocarcinoma_images = [f'{test_img_dir_path}/adenocarcinoma/{i}' for i in listdir(f'{test_img_dir_path}/adenocarcinoma')]\n",
    "test_largecell_carcinoma_images = [f'{test_img_dir_path}/large.cell.carcinoma/{i}' for i in listdir(f'{test_img_dir_path}/large.cell.carcinoma')]\n",
    "test_squamouscell_carcinoma_images = [f'{test_img_dir_path}/squamous.cell.carcinoma/{i}' for i in listdir(f'{test_img_dir_path}/squamous.cell.carcinoma')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabed18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cancer_df = pd.DataFrame(columns=['image_id','label'])\n",
    "val_cancer_df = pd.DataFrame(columns=['image_id','label'])\n",
    "test_cancer_df = pd.DataFrame(columns=['image_id','label'])\n",
    "\n",
    "train_cancer_df['image_id'] = train_normal_images + train_adenocarcinoma_images + train_largecell_carcinoma_images + train_squamouscell_carcinoma_images\n",
    "train_cancer_df['label'] = np.zeros_like(train_normal_images,dtype=int).tolist()+np.ones_like(train_adenocarcinoma_images,dtype=int).tolist()+np.full_like(train_largecell_carcinoma_images,2,dtype=int).tolist()+np.full_like(train_squamouscell_carcinoma_images,3,dtype=int).tolist()\n",
    "val_cancer_df['image_id'] = valid_normal_images + valid_adenocarcinoma_images + valid_largecell_carcinoma_images + valid_squamouscell_carcinoma_images \n",
    "val_cancer_df['label'] = np.zeros_like(valid_normal_images,dtype=int).tolist() + np.ones_like(valid_adenocarcinoma_images,dtype=int).tolist() + np.full_like(valid_largecell_carcinoma_images,2,dtype=int).tolist() + np.full_like(valid_squamouscell_carcinoma_images,3,dtype=int).tolist()\n",
    "test_cancer_df['image_id'] = test_normal_images + test_adenocarcinoma_images + test_largecell_carcinoma_images + test_squamouscell_carcinoma_images\n",
    "test_cancer_df['label'] = np.zeros_like(test_normal_images,dtype=int).tolist() + np.ones_like(test_adenocarcinoma_images,dtype=int).tolist() + np.full_like(test_largecell_carcinoma_images,2,dtype=int).tolist() + np.full_like(test_squamouscell_carcinoma_images,3,dtype=int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e781fa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/train/normal/19 - Copy.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/train/normal/11 - Copy (2) - Copy.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/train/normal/n6 - Copy.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/train/normal/7.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/train/normal/16 - Copy.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_id  label\n",
       "0             images/train/normal/19 - Copy.png      0\n",
       "1  images/train/normal/11 - Copy (2) - Copy.png      0\n",
       "2             images/train/normal/n6 - Copy.jpg      0\n",
       "3                     images/train/normal/7.png      0\n",
       "4             images/train/normal/16 - Copy.png      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cancer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48ac8d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613\n",
      "72\n",
      "315\n"
     ]
    }
   ],
   "source": [
    "print(len(train_cancer_df))\n",
    "print(len(val_cancer_df))\n",
    "print(len(test_cancer_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b87131c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>images/valid/normal/7.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>images/valid/normal/6 - Copy (3).png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>images/valid/normal/004007_01_01_519.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>images/valid/normal/7 - Copy (2).png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>images/valid/normal/6 - Copy.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>images/valid/normal/4 (2).png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>images/valid/normal/003828_02_01_174.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>images/valid/normal/4 - Copy (2).png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>images/valid/normal/5.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>images/valid/normal/004162_01_01_150.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>images/valid/normal/7 - Copy (3).png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>images/valid/normal/6 - Copy (2) - Copy.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>images/valid/normal/8 - Copy (3).png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>images/valid/adenocarcinoma/000109 (8).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>images/valid/adenocarcinoma/000109 (3).png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_id  label\n",
       "0                     images/valid/normal/7.png      0\n",
       "1          images/valid/normal/6 - Copy (3).png      0\n",
       "2      images/valid/normal/004007_01_01_519.png      0\n",
       "3          images/valid/normal/7 - Copy (2).png      0\n",
       "4              images/valid/normal/6 - Copy.png      0\n",
       "5                 images/valid/normal/4 (2).png      0\n",
       "6      images/valid/normal/003828_02_01_174.png      0\n",
       "7          images/valid/normal/4 - Copy (2).png      0\n",
       "8                     images/valid/normal/5.png      0\n",
       "9      images/valid/normal/004162_01_01_150.png      0\n",
       "10         images/valid/normal/7 - Copy (3).png      0\n",
       "11  images/valid/normal/6 - Copy (2) - Copy.png      0\n",
       "12         images/valid/normal/8 - Copy (3).png      0\n",
       "13   images/valid/adenocarcinoma/000109 (8).png      1\n",
       "14   images/valid/adenocarcinoma/000109 (3).png      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_cancer_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ef6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungsCancerDetectionDataset(Dataset):\n",
    "    def __init__(self, annotations_file,transform=None, target_transform=None):\n",
    "        self.img_labels = annotations_file\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = str(self.img_labels.iloc[idx].image_id)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (400,400))\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        image = torch.as_tensor(image)\n",
    "        image = image.float()\n",
    "        image = image/255\n",
    "        label = torch.as_tensor(self.img_labels.iloc[idx].label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b1933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungsCancerDetectionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = tv.models.densenet121()\n",
    "        self.nn_detection = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1000,4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        logits = self.nn_detection(x)\n",
    "        return logits\n",
    "    \n",
    "    def predict(self,logits):\n",
    "        preds = self.forward(logits)\n",
    "        preds = torch.sigmoid(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a4310c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(name, model):\n",
    "    torch.save(model.state_dict(), f'{name}.tph')\n",
    "\n",
    "def load_model(model, name, path='.'):\n",
    "    data = torch.load(os.path.join(path, f'{name}.tph'))\n",
    "    model.load_state_dict(data)\n",
    "    return model\n",
    "\n",
    "def gc_collect():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a173ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(ds_train, logger, name):\n",
    "    \n",
    "    dl_train = torch.utils.data.DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True,num_workers=os.cpu_count())\n",
    "    model = LungsCancerDetectionModel().to(DEVICE)\n",
    "    optim = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=0.001, epochs=NB_EPOCHS,\n",
    "                                                steps_per_epoch=min(MAX_TRAIN_BATCHES, len(dl_train)),\n",
    "                                                pct_start=0.3)\n",
    "    model.train()\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for epoch in tqdm(range(NB_EPOCHS), desc='Epoch'):\n",
    "        with tqdm(dl_train, desc='Train') as progress:\n",
    "\n",
    "            for batch_idx, (X, y) in enumerate(progress):\n",
    "\n",
    "                if batch_idx >= MAX_TRAIN_BATCHES:\n",
    "                    save_model(name, model)\n",
    "                    break\n",
    "\n",
    "                optim.zero_grad()\n",
    "                with autocast():\n",
    "                    pred = model.forward(X.to(DEVICE))\n",
    "                    pred = pred.squeeze()\n",
    "                    loss = torch.nn.functional.cross_entropy(pred,y.to(DEVICE))\n",
    "\n",
    "                    if np.isinf(loss.item()) or np.isnan(loss.item()):\n",
    "                        print(f'Bad loss, skipping the batch {batch_idx}')\n",
    "                        del loss, pred\n",
    "                        gc_collect()\n",
    "                        continue\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optim)\n",
    "                scaler.update()\n",
    "                scheduler.step()\n",
    "\n",
    "                logger.log({'training loss': (loss.item()),\n",
    "                            'learning rate': scheduler.get_last_lr()[0],\n",
    "                            'epoch': epoch})\n",
    "                \n",
    "    save_model(name, model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55114529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrbizet\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rbizet/Desktop/DS50/wandb/run-20230505_003903-c8mmtd32</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rbizet/DS50/runs/c8mmtd32' target=\"_blank\">DenseNet_V2</a></strong> to <a href='https://wandb.ai/rbizet/DS50' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rbizet/DS50' target=\"_blank\">https://wandb.ai/rbizet/DS50</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rbizet/DS50/runs/c8mmtd32' target=\"_blank\">https://wandb.ai/rbizet/DS50/runs/c8mmtd32</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbizet/Desktop/DS50/DS50Env/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:120: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11ec6a7970c4347ac2bf0372a615506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3960b40743974246b7652b2bfa8ee6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbizet/Desktop/DS50/DS50Env/lib/python3.9/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c4cdda1c944f4095e6d2a11a749c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5b125bd11e420cbdc97009c78870ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c55dfa91c624dca82ee77005ece4894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅█████████████</td></tr><tr><td>learning rate</td><td>▁▁▂▂▃▄▅▆▇▇███████▇▇▇▇▆▆▅▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>training loss</td><td>▃▁▇▃▅▂█▄▄▅▃▄▆▃▄▃▃▇▅▄▅▂▃▄▁▄▄▃▃▄▃▄▅▃▁▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>training loss</td><td>1.49206</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DenseNet_V2</strong> at: <a href='https://wandb.ai/rbizet/DS50/runs/c8mmtd32' target=\"_blank\">https://wandb.ai/rbizet/DS50/runs/c8mmtd32</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230505_003903-c8mmtd32/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project='DS50', name=VERSION) as run:\n",
    "    gc_collect()\n",
    "    ds_train = LungsCancerDetectionDataset(train_cancer_df)\n",
    "    model = train_model(ds_train,run,VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55956b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, ds, max_batches):\n",
    "    model = model.to(DEVICE)\n",
    "    dl_val = torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        losses = []\n",
    "        with tqdm(dl_val, desc='Val') as progress:\n",
    "            for i, (X, y) in enumerate(progress):\n",
    "                with autocast():\n",
    "                    pred = model.forward(X.to(DEVICE))\n",
    "                    pred = pred.squeeze()\n",
    "                    loss = torch.nn.functional.cross_entropy(pred,y.to(DEVICE))\n",
    "                    pred = torch.sigmoid(pred)\n",
    "                    preds.append(pred.cpu())\n",
    "                    losses.append(loss)\n",
    "                    labels.append(y.cpu().numpy())\n",
    "                    \n",
    "                if i >= max_batches:\n",
    "                    break\n",
    "        preds = torch.concat(preds).cpu().numpy()\n",
    "        labels = np.concatenate(labels)\n",
    "        return np.mean(losses), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90689abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d692508fd4264d1c92de3fa6fbc097e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss 0.9335488080978394\n",
      "                                             image_id  label    normal   \n",
      "0                           images/valid/normal/7.png      0  1.000000  \\\n",
      "1                images/valid/normal/6 - Copy (3).png      0  1.000000   \n",
      "2            images/valid/normal/004007_01_01_519.png      0  1.000000   \n",
      "3                images/valid/normal/7 - Copy (2).png      0  1.000000   \n",
      "4                    images/valid/normal/6 - Copy.png      0  1.000000   \n",
      "..                                                ...    ...       ...   \n",
      "67  images/valid/squamous.cell.carcinoma/000115 (5...      3  0.089464   \n",
      "68  images/valid/squamous.cell.carcinoma/000118 (5...      3  0.274495   \n",
      "69  images/valid/squamous.cell.carcinoma/000118 (4...      3  0.212546   \n",
      "70  images/valid/squamous.cell.carcinoma/000116 (2...      3  0.131298   \n",
      "71  images/valid/squamous.cell.carcinoma/000108 (3...      3  0.099356   \n",
      "\n",
      "    adenocarcinoma  largecell_carcinoma  squamouscell_carcinoma  \n",
      "0         0.000166         0.000000e+00            2.763220e-35  \n",
      "1         0.016718         6.734538e-23            9.584891e-17  \n",
      "2         0.775732         1.570449e-09            1.518904e-06  \n",
      "3         0.000037         0.000000e+00            0.000000e+00  \n",
      "4         0.003304         8.393401e-29            3.653848e-21  \n",
      "..             ...                  ...                     ...  \n",
      "67        0.735747         6.407488e-01            7.187365e-01  \n",
      "68        0.588344         5.743365e-01            5.961155e-01  \n",
      "69        0.624051         5.928512e-01            6.286334e-01  \n",
      "70        0.690242         6.212593e-01            6.818272e-01  \n",
      "71        0.716991         6.394905e-01            7.077771e-01  \n",
      "\n",
      "[72 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def gen_model_predictions(model, val_cancer_df, max_batches):\n",
    "    ds_eval = LungsCancerDetectionDataset(val_cancer_df)\n",
    "    loss, preds = evaluate_model(model, ds_eval, max_batches)\n",
    "    df_pred = pd.DataFrame(data=preds,columns=['normal','adenocarcinoma','largecell_carcinoma','squamouscell_carcinoma'])\n",
    "    df_train_predictions = pd.concat(\n",
    "            [val_cancer_df.head(len(df_pred)).reset_index(drop=True),df_pred],axis=1\n",
    "    )\n",
    "    return df_train_predictions ,loss\n",
    "\n",
    "val_df_pred, val_loss = gen_model_predictions(model,val_cancer_df,MAX_VAL_BATCHES)\n",
    "print(f'Val loss {val_loss}')\n",
    "print(val_df_pred)\n",
    "val_df_pred.to_csv(f'val_predictions_{VERSION}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "150d9182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c3f22d9e5145e297beaa07d8d72864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val:   0%|          | 0/158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rbizet/Desktop/DS50/DS50Env/lib/python3.9/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 0.8809480667114258\n",
      "                                              image_id  label    normal   \n",
      "0          images/test/normal/11 - Copy (2) - Copy.png      0  1.000000  \\\n",
      "1                             images/test/normal/7.png      0  1.000000   \n",
      "2                 images/test/normal/11 - Copy (3).png      0  1.000000   \n",
      "3                  images/test/normal/6 - Copy (3).png      0  1.000000   \n",
      "4                            images/test/normal/23.png      0  1.000000   \n",
      "..                                                 ...    ...       ...   \n",
      "307  images/test/squamous.cell.carcinoma/000114 (3)...      3  0.196547   \n",
      "308  images/test/squamous.cell.carcinoma/000139 (6)...      3  0.188168   \n",
      "309  images/test/squamous.cell.carcinoma/000163 (6)...      3  0.052829   \n",
      "310  images/test/squamous.cell.carcinoma/000168 (2)...      3  0.066711   \n",
      "311  images/test/squamous.cell.carcinoma/000126 (4)...      3  0.141513   \n",
      "\n",
      "     adenocarcinoma  largecell_carcinoma  squamouscell_carcinoma  \n",
      "0          0.000501         0.000000e+00            1.959007e-34  \n",
      "1          0.000166         0.000000e+00            2.763220e-35  \n",
      "2          0.000425         0.000000e+00            1.337395e-34  \n",
      "3          0.016718         6.734538e-23            9.584891e-17  \n",
      "4          0.000109         0.000000e+00            1.578133e-36  \n",
      "..              ...                  ...                     ...  \n",
      "307        0.649179         5.922120e-01            6.390921e-01  \n",
      "308        0.765166         5.310295e-01            6.638297e-01  \n",
      "309        0.810192         6.511794e-01            7.674279e-01  \n",
      "310        0.787921         6.404579e-01            7.475482e-01  \n",
      "311        0.692432         6.089860e-01            6.748062e-01  \n",
      "\n",
      "[312 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "test_df_pred, test_loss = gen_model_predictions(model,test_cancer_df,MAX_TEST_BATCHES)\n",
    "print(f'Test loss {test_loss}')\n",
    "print(test_df_pred)\n",
    "test_df_pred.to_csv(f'test_predictions_{VERSION}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8dd3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS50Env",
   "language": "python",
   "name": "ds50env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
